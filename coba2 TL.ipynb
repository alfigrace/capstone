{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install libportaudio2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v21CZHlUZ5Ey",
        "outputId": "35cc6907-ffdb-43d1-e3d1-edac5d28585c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 64.6 kB of archives.\n",
            "After this operation, 215 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Fetched 64.6 kB in 0s (1,118 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 155203 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CCytfGlqZ42y",
        "outputId": "2191e1a4-ef04-4eb2-ee23-f3e9d663ae17"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite-model-maker\n",
            "  Downloading tflite_model_maker-0.4.0-py3-none-any.whl (642 kB)\n",
            "\u001b[K     |████████████████████████████████| 642 kB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.29.13 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.29.28)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-datasets>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (4.0.1)\n",
            "Collecting tf-models-official==2.3.0\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[K     |████████████████████████████████| 840 kB 39.2 MB/s \n",
            "\u001b[?25hCollecting scann>=1.2.6\n",
            "  Downloading scann-1.2.6-cp37-cp37m-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.24.3)\n",
            "Requirement already satisfied: librosa==0.8.1 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.8.1)\n",
            "Requirement already satisfied: matplotlib<3.5.0,>=3.0.3 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (3.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.5\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting fire>=0.3.1\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (1.0.0)\n",
            "Collecting flatbuffers==1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (0.12.0)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (7.1.2)\n",
            "Collecting lxml>=4.6.1\n",
            "  Downloading lxml-4.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tflite-model-maker) (2.8.0)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 13.8 MB/s \n",
            "\u001b[?25hCollecting neural-structured-learning>=1.3.1\n",
            "  Downloading neural_structured_learning-1.3.1-py2.py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 71.2 MB/s \n",
            "\u001b[?25hCollecting numba==0.53\n",
            "  Downloading numba-0.53.0-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 57.6 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting tflite-support>=0.4.0\n",
            "  Downloading tflite_support-0.4.0-cp37-cp37m-manylinux2014_x86_64.whl (42.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting tensorflowjs>=2.4.0\n",
            "  Downloading tensorflowjs-3.15.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons>=0.11.2\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.6.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (2.1.9)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (4.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (21.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.1.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (1.0.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.1->tflite-model-maker) (0.2.2)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.53->tflite-model-maker) (57.4.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.5.12)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.8 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.3.5)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 50.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (5.4.8)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.12.11)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (0.5.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.3.0->tflite-model-maker) (1.21.0)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.1->tflite-model-maker) (1.1.0)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.31.5)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.17.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (1.56.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2022.1)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.17.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (4.2.4)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker) (1.0.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (4.64.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (2021.10.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<3.5.0,>=3.0.3->tflite-model-maker) (4.2.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from neural-structured-learning>=1.3.1->tflite-model-maker) (21.4.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.1->tflite-model-maker) (1.4.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.8.1->tflite-model-maker) (2.21)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.14.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.44.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.25.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (14.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tflite-model-maker) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 67.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite-model-maker) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.6.0->tflite-model-maker) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.3.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker) (3.2.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons>=0.11.2->tflite-model-maker) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (2.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.1.7)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.16.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (5.7.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (0.3.4)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets>=2.1.0->tflite-model-maker) (1.7.0)\n",
            "Collecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.4.4-py3-none-any.whl (31 kB)\n",
            "Collecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.9.2-py2.py3-none-any.whl (213 kB)\n",
            "\u001b[K     |████████████████████████████████| 213 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.12.0\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker) (1.3)\n",
            "Building wheels for collected packages: fire, py-cpuinfo\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=70bbb28df359866dd07726d505d113bdb4ad9c14ea802ce1f9a1da55edc3c166\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=49fee7213aaef4b1990d167a8bdbec1a2a1f10e348f331d05b4654eb33920e87\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "Successfully built fire py-cpuinfo\n",
            "Installing collected packages: protobuf, llvmlite, tf-estimator-nightly, numba, flatbuffers, tf-slim, tensorflow-model-optimization, tensorflow-addons, sounddevice, sentencepiece, PyYAML, pybind11, py-cpuinfo, opencv-python-headless, dataclasses, tflite-support, tf-models-official, tensorflowjs, scann, neural-structured-learning, lxml, fire, tflite-model-maker\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed PyYAML-6.0 dataclasses-0.6 fire-0.4.0 flatbuffers-1.12 llvmlite-0.36.0 lxml-4.8.0 neural-structured-learning-1.3.1 numba-0.53.0 opencv-python-headless-4.5.5.64 protobuf-3.20.1 py-cpuinfo-8.0.0 pybind11-2.9.2 scann-1.2.6 sentencepiece-0.1.96 sounddevice-0.4.4 tensorflow-addons-0.16.1 tensorflow-model-optimization-0.7.2 tensorflowjs-3.15.0 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-model-maker-0.4.0 tflite-support-0.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dataclasses",
                  "flatbuffers",
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gycf8Pn7eFrK",
        "outputId": "4fdddddb-11c7-4305-8af4-3c96d65c5796"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "qlfwhR-ysult"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tflite_model_maker.config import QuantizationConfig"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQvOUe8B2utt",
        "outputId": "d76f1753-4598-4226-a46e-f6cd0e867a08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "69gmaxuA2zlU",
        "outputId": "68f14c8a-c21f-4e01-cbff-fa32537e8a0f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cc1f2c48-2105-49ae-84f1-c37ba351e2dc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cc1f2c48-2105-49ae-84f1-c37ba351e2dc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 69 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei0n7TSm26sA",
        "outputId": "a3de96c2-1808-40bc-925f-bbf68f0a94e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                       deadline             category            reward  teamCount  userHasEntered  \n",
            "--------------------------------------------------------  -------------------  ---------------  ---------  ---------  --------------  \n",
            "mpetitions/contradictory-my-dear-watson                   2030-07-01 23:59:00  Getting Started     Prizes         39           False  \n",
            "mpetitions/gan-getting-started                            2030-07-01 23:59:00  Getting Started     Prizes        138           False  \n",
            "mpetitions/store-sales-time-series-forecasting            2030-06-30 23:59:00  Getting Started  Knowledge        898           False  \n",
            "mpetitions/tpu-getting-started                            2030-06-03 23:59:00  Getting Started  Knowledge        162           False  \n",
            "mpetitions/digit-recognizer                               2030-01-01 00:00:00  Getting Started  Knowledge       2063           False  \n",
            "mpetitions/titanic                                        2030-01-01 00:00:00  Getting Started  Knowledge      14129           False  \n",
            "mpetitions/house-prices-advanced-regression-techniques    2030-01-01 00:00:00  Getting Started  Knowledge       4346           False  \n",
            "mpetitions/connectx                                       2030-01-01 00:00:00  Getting Started  Knowledge        227           False  \n",
            "mpetitions/nlp-getting-started                            2030-01-01 00:00:00  Getting Started  Knowledge        895           False  \n",
            "mpetitions/spaceship-titanic                              2030-01-01 00:00:00  Getting Started  Knowledge       2067           False  \n",
            "mpetitions/competitive-data-science-predict-future-sales  2022-12-31 23:59:00  Playground           Kudos      14740           False  \n",
            "mpetitions/AI4Code                                        2022-08-11 23:59:00  Featured          $150,000         56           False  \n",
            "mpetitions/smartphone-decimeter-2022                      2022-07-29 23:59:00  Research           $10,000        100           False  \n",
            "mpetitions/ubiquant-market-prediction                     2022-07-18 23:59:00  Featured          $100,000       2810           False  \n",
            "mpetitions/uw-madison-gi-tract-image-segmentation         2022-07-14 23:59:00  Research           $25,000        447           False  \n",
            "mpetitions/kore-2022                                      2022-07-12 23:59:00  Featured           $15,000        195           False  \n",
            "mpetitions/foursquare-location-matching                   2022-07-07 23:59:00  Featured           $25,000        436           False  \n",
            "mpetitions/jpx-tokyo-stock-exchange-prediction            2022-07-05 23:59:00  Featured           $63,000        938           False  \n",
            "mpetitions/phase-ii-widsdatathon2022                      2022-06-30 23:59:00  Analytics            Kudos          0           False  \n",
            "mpetitions/us-patent-phrase-to-phrase-matching            2022-06-20 23:59:00  Featured           $25,000       1154           False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d anefiamutiaraatha/dataset-tanaman-herbal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWqoMM6E3AAP",
        "outputId": "993f2094-003e-430f-f1e0-ffd57fe74afa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset-tanaman-herbal.zip to /content\n",
            "100% 3.35G/3.35G [00:48<00:00, 101MB/s] \n",
            "100% 3.35G/3.35G [00:48<00:00, 74.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the downloaded zip file\n",
        "!unzip /content/dataset-tanaman-herbal.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGRZx_Qr3ChX",
        "outputId": "b52450e9-08ac-4b77-987c-ae5474b67dca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dataset-tanaman-herbal.zip\n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (100).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (81).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (82).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (83).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (84).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (85).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (86).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (87).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (88).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (89).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (90).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (91).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (92).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (93).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (94).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (95).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (96).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (97).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (98).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Jambu Biji/jambu biji (99).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (100).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (81).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (82).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (83).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (84).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (85).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (86).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (87).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (88).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (89).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (90).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (91).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (92).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (93).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (94).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (95).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (96).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (97).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (98).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kari/KARI (99).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (100).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (81).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (82).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (83).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (84).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (85).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (86).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (87).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (88).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (89).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (90).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (91).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (92).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (93).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (94).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (95).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (96).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (97).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (98).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kemangi/daun kemangi (99).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (100).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (81).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (82).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (83).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (84).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (85).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (86).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (87).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (88).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (89).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (90).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (91).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (92).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (93).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (94).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (95).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (96).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (97).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (98).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Kunyit/kunyit (99).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (100).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (81).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (82).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (83).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (84).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (85).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (86).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (87).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (88).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (89).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (90).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (91).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (92).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (93).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (94).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (95).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (96).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (97).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (98).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Mint/mint (99).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (100).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (81).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (82).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (83).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (84).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (85).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (86).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (87).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (88).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (89).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (90).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (91).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (92).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (93).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (94).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (95).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (96).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (97).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (98).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Pepaya/pepaya (99).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (100).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (81).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (82).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (83).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (84).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (85).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (86).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (87).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (88).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (89).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (90).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (91).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (92).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (93).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (94).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (95).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (96).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (97).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (98).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirih/Sirih (99).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (100).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (81).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (82).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (83).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (84).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (85).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (86).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (87).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (88).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (89).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (90).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (91).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (92).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (93).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (94).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (95).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (96).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (97).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (98).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Daun Sirsak/sirsakk (99).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (100).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (81).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (82).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (83).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (84).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (85).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (86).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (87).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (88).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (89).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (90).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (91).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (92).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (93).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (94).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (95).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (96).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (97).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (98).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Lidah Buaya/lidah buaya (99).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (100).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (81).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (82).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (83).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (84).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (85).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (86).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (87).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (88).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (89).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (90).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (91).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (92).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (93).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (94).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (95).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (96).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (97).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (98).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Testing/Teh Hijau/Teh Hijauu (99).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (1).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (10).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (11).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (12).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (13).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (14).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (15).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (16).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (17).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (18).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (19).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (2).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (20).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (21).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (22).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (23).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (24).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (25).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (26).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (27).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (28).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (29).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (3).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (30).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (31).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (32).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (33).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (34).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (35).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (36).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (37).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (38).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (39).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (4).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (40).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (41).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (42).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (43).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (44).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (45).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (46).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (47).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (48).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (49).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (5).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (50).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (51).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (52).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (53).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (54).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (55).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (56).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (57).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (58).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (59).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (6).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (60).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (61).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (62).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (63).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (64).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (65).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (66).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (67).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (68).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (69).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (7).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (70).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (71).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (72).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (73).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (74).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (75).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (76).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (77).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (78).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (79).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (8).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (80).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Jambu Biji/jambu biji (9).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (1).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (10).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (11).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (12).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (13).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (14).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (15).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (16).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (17).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (18).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (19).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (2).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (20).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (21).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (22).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (23).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (24).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (25).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (26).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (27).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (28).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (29).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (3).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (30).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (31).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (32).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (33).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (34).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (35).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (36).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (37).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (38).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (39).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (4).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (40).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (41).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (42).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (43).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (44).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (45).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (46).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (47).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (48).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (49).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (5).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (50).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (51).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (52).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (53).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (54).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (55).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (56).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (57).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (58).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (59).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (6).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (60).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (61).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (62).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (63).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (64).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (65).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (66).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (67).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (68).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (69).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (7).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (70).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (71).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (72).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (73).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (74).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (75).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (76).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (77).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (78).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (79).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (8).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (80).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kari/KARI (9).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (1).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (10).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (11).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (12).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (13).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (14).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (15).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (16).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (17).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (18).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (19).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (2).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (20).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (21).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (22).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (23).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (24).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (25).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (26).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (27).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (28).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (29).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (3).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (30).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (31).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (32).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (33).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (34).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (35).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (36).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (37).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (38).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (39).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (4).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (40).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (41).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (42).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (43).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (44).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (45).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (46).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (47).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (48).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (49).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (5).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (50).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (51).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (52).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (53).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (54).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (55).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (56).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (57).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (58).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (59).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (6).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (60).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (61).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (62).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (63).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (64).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (65).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (66).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (67).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (68).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (69).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (7).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (70).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (71).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (72).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (73).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (74).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (75).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (76).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (77).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (78).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (79).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (8).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (80).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kemangi/daun kemangi (9).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (1).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (10).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (11).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (12).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (13).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (14).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (15).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (16).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (17).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (18).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (19).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (2).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (20).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (21).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (22).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (23).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (24).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (25).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (26).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (27).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (28).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (29).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (3).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (30).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (31).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (32).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (33).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (34).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (35).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (36).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (37).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (38).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (39).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (4).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (40).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (41).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (42).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (43).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (44).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (45).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (46).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (47).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (48).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (49).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (5).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (50).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (51).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (52).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (53).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (54).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (55).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (56).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (57).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (58).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (59).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (6).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (60).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (61).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (62).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (63).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (64).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (65).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (66).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (67).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (68).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (69).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (7).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (70).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (71).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (72).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (73).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (74).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (75).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (76).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (77).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (78).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (79).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (8).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (80).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Kunyit/kunyit (9).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (1).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (10).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (11).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (12).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (13).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (14).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (15).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (16).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (17).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (18).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (19).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (2).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (20).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (21).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (22).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (23).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (24).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (25).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (26).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (27).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (28).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (29).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (3).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (30).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (31).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (32).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (33).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (34).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (35).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (36).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (37).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (38).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (39).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (4).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (40).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (41).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (42).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (43).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (44).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (45).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (46).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (47).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (48).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (49).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (5).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (50).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (51).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (52).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (53).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (54).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (55).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (56).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (57).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (58).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (59).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (6).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (60).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (61).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (62).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (63).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (64).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (65).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (66).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (67).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (68).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (69).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (7).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (70).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (71).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (72).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (73).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (74).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (75).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (76).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (77).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (78).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (79).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (8).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (80).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Mint/mint (9).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (1).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (10).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (11).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (12).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (13).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (14).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (15).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (16).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (17).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (18).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (19).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (2).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (20).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (21).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (22).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (23).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (24).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (25).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (26).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (27).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (28).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (29).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (3).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (30).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (31).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (32).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (33).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (34).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (35).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (36).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (37).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (38).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (39).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (4).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (40).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (41).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (42).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (43).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (44).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (45).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (46).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (47).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (48).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (49).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (5).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (50).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (51).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (52).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (53).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (54).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (55).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (56).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (57).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (58).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (59).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (6).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (60).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (61).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (62).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (63).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (64).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (65).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (66).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (67).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (68).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (69).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (7).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (70).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (71).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (72).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (73).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (74).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (75).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (76).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (77).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (78).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (79).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (8).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (80).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Pepaya/pepaya (9).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (1).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (10).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (11).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (12).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (13).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (14).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (15).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (16).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (17).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (18).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (19).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (2).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (20).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (21).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (22).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (23).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (24).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (25).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (26).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (27).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (28).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (29).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (3).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (30).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (31).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (32).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (33).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (34).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (35).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (36).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (37).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (38).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (39).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (4).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (40).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (41).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (42).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (43).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (44).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (45).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (46).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (47).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (48).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (49).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (5).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (50).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (51).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (52).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (53).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (54).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (55).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (56).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (57).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (58).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (59).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (6).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (60).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (61).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (62).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (63).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (64).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (65).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (66).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (67).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (68).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (69).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (7).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (70).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (71).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (72).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (73).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (74).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (75).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (76).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (77).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (78).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (79).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (8).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (80).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirih/Sirih (9).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (1).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (10).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (11).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (12).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (13).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (14).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (15).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (16).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (17).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (18).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (19).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (2).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (20).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (21).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (22).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (23).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (24).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (25).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (26).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (27).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (28).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (29).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (3).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (30).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (31).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (32).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (33).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (34).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (35).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (36).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (37).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (38).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (39).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (4).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (40).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (41).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (42).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (43).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (44).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (45).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (46).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (47).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (48).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (49).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (5).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (50).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (51).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (52).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (53).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (54).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (55).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (56).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (57).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (58).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (59).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (6).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (60).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (61).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (62).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (63).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (64).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (65).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (66).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (67).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (68).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (69).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (7).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (70).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (71).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (72).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (73).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (74).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (75).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (76).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (77).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (78).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (79).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (8).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (80).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Daun Sirsak/sirsakk (9).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (1).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (10).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (11).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (12).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (13).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (14).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (15).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (16).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (17).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (18).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (19).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (2).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (20).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (21).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (22).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (23).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (24).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (25).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (26).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (27).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (28).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (29).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (3).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (30).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (31).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (32).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (33).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (34).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (35).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (36).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (37).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (38).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (39).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (4).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (40).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (41).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (42).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (43).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (44).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (45).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (46).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (47).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (48).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (49).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (5).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (50).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (51).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (52).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (53).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (54).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (55).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (56).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (57).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (58).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (59).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (6).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (60).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (61).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (62).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (63).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (64).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (65).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (66).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (67).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (68).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (69).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (7).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (70).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (71).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (72).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (73).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (74).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (75).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (76).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (77).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (78).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (79).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (8).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (80).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Lidah Buaya/lidah buaya (9).JPG  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (1).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (10).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (11).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (12).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (13).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (14).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (15).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (16).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (17).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (18).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (19).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (2).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (20).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (21).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (22).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (23).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (24).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (25).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (26).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (27).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (28).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (29).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (3).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (30).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (31).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (32).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (33).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (34).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (35).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (36).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (37).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (38).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (39).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (4).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (40).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (41).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (42).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (43).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (44).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (45).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (46).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (47).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (48).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (49).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (5).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (50).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (51).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (52).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (53).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (54).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (55).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (56).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (57).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (58).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (59).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (6).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (60).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (61).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (62).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (63).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (64).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (65).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (66).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (67).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (68).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (69).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (7).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (70).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (71).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (72).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (73).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (74).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (75).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (76).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (77).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (78).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (79).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (8).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (80).jpg  \n",
            "  inflating: DATASET TANAMAN HERBAL/Data Training/Teh Hijau/Teh Hijauu (9).jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/DATASET TANAMAN HERBAL/Data Training'\n",
        "validation_dir = '/content/DATASET TANAMAN HERBAL/Data Testing'"
      ],
      "metadata": {
        "id": "WsubphzB3PXK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)"
      ],
      "metadata": {
        "id": "Ech0BpPi6Udr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                      batch_size=32, \n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXnfS-WW_lE4",
        "outputId": "2730fdd6-adca-4336-e456-91d8d928ee33"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 800 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "2VWV18R46WMu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = validation_datagen.flow_from_directory(directory=validation_dir,\n",
        "                                                                batch_size=32, \n",
        "                                                                class_mode=\"categorical\",\n",
        "                                                                target_size=(224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNV2Ddff_7QZ",
        "outputId": "7ff27f18-ee2b-46c8-e86d-703f1bc12cc9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = InceptionV3(input_shape = (224, 224, 3),\n",
        "                                include_top = False,\n",
        "                                weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n10MAHgIK78j",
        "outputId": "0a69a925-6575-4983-cac6-d8265f4df766"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pretrained_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "hq3dS4qCL2qY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pretrained_model.get_layer('mixed5')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75y8s6QrL9DB",
        "outputId": "b2d574ed-049b-4de7-e614-a44f25d9114c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last layer output shape:  (None, 12, 12, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(10, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "GoqBmab3MFJL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(pretrained_model.input, x)"
      ],
      "metadata": {
        "id": "ST_nJezLMG6f"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvCnHBpqML5_",
        "outputId": "3fd2d6c1-52ae-485f-ca53-5279b04a308d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 111, 111, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 111, 111, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 111, 111, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 109, 109, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 109, 109, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 109, 109, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 109, 109, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 109, 109, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 109, 109, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 54, 54, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 54, 54, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 54, 54, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 54, 54, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 52, 52, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 52, 52, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 52, 52, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 25, 25, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 25, 25, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 25, 25, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 25, 25, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 25, 25, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 25, 25, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 25, 25, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 25, 25, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 25, 25, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 25, 25, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 25, 25, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 25, 25, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 25, 25, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 25, 25, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 25, 25, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 25, 25, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 25, 25, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 25, 25, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 25, 25, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 25, 25, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 25, 25, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 25, 25, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 25, 25, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 25, 25, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 25, 25, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 25, 25, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 25, 25, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 25, 25, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 25, 25, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 25, 25, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 25, 25, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 25, 25, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 25, 25, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 25, 25, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 25, 25, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 25, 25, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 25, 25, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 25, 25, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 25, 25, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 25, 25, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 25, 25, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 25, 25, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 25, 25, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 25, 25, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 25, 25, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 25, 25, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 25, 25, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 110592)       0           ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 512)          56623616    ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 512)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 10)           5130        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 61,767,402\n",
            "Trainable params: 56,628,746\n",
            "Non-trainable params: 5,138,656\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator, \n",
        "                     epochs=20, \n",
        "                     steps_per_epoch=10, \n",
        "                     validation_data=validation_generator, \n",
        "                     validation_steps=3,\n",
        "                     verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghoTrSfuMUIu",
        "outputId": "78b2c818-4c77-409f-8f22-9d99b026ec1c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "10/10 [==============================] - 135s 13s/step - loss: 3.9345 - accuracy: 0.3187 - val_loss: 2.4283 - val_accuracy: 0.4688\n",
            "Epoch 2/20\n",
            "10/10 [==============================] - 125s 13s/step - loss: 1.1212 - accuracy: 0.6375 - val_loss: 1.2364 - val_accuracy: 0.6562\n",
            "Epoch 3/20\n",
            "10/10 [==============================] - 128s 13s/step - loss: 0.6109 - accuracy: 0.8031 - val_loss: 1.1706 - val_accuracy: 0.6562\n",
            "Epoch 4/20\n",
            "10/10 [==============================] - 129s 13s/step - loss: 0.3369 - accuracy: 0.9062 - val_loss: 0.7692 - val_accuracy: 0.7396\n",
            "Epoch 5/20\n",
            "10/10 [==============================] - 130s 13s/step - loss: 0.3130 - accuracy: 0.8906 - val_loss: 0.7461 - val_accuracy: 0.7708\n",
            "Epoch 6/20\n",
            "10/10 [==============================] - 131s 13s/step - loss: 0.1833 - accuracy: 0.9531 - val_loss: 0.5690 - val_accuracy: 0.8333\n",
            "Epoch 7/20\n",
            "10/10 [==============================] - 125s 13s/step - loss: 0.2326 - accuracy: 0.9219 - val_loss: 0.5808 - val_accuracy: 0.7917\n",
            "Epoch 8/20\n",
            "10/10 [==============================] - 125s 13s/step - loss: 0.1524 - accuracy: 0.9625 - val_loss: 0.4728 - val_accuracy: 0.8333\n",
            "Epoch 9/20\n",
            "10/10 [==============================] - 128s 13s/step - loss: 0.1436 - accuracy: 0.9688 - val_loss: 0.3276 - val_accuracy: 0.8542\n",
            "Epoch 10/20\n",
            "10/10 [==============================] - 130s 13s/step - loss: 0.1045 - accuracy: 0.9594 - val_loss: 0.4659 - val_accuracy: 0.8438\n",
            "Epoch 11/20\n",
            "10/10 [==============================] - 121s 12s/step - loss: 0.1116 - accuracy: 0.9656 - val_loss: 0.8108 - val_accuracy: 0.8021\n",
            "Epoch 12/20\n",
            "10/10 [==============================] - 129s 13s/step - loss: 0.1306 - accuracy: 0.9500 - val_loss: 0.2602 - val_accuracy: 0.8750\n",
            "Epoch 13/20\n",
            "10/10 [==============================] - 132s 14s/step - loss: 0.0706 - accuracy: 0.9781 - val_loss: 0.3315 - val_accuracy: 0.8646\n",
            "Epoch 14/20\n",
            "10/10 [==============================] - 127s 13s/step - loss: 0.0706 - accuracy: 0.9781 - val_loss: 0.3418 - val_accuracy: 0.9062\n",
            "Epoch 15/20\n",
            "10/10 [==============================] - 127s 13s/step - loss: 0.0722 - accuracy: 0.9781 - val_loss: 0.2567 - val_accuracy: 0.9167\n",
            "Epoch 16/20\n",
            "10/10 [==============================] - 124s 13s/step - loss: 0.0713 - accuracy: 0.9781 - val_loss: 0.2319 - val_accuracy: 0.8854\n",
            "Epoch 17/20\n",
            "10/10 [==============================] - 122s 12s/step - loss: 0.0485 - accuracy: 0.9906 - val_loss: 0.3911 - val_accuracy: 0.8958\n",
            "Epoch 18/20\n",
            "10/10 [==============================] - 128s 13s/step - loss: 0.1058 - accuracy: 0.9688 - val_loss: 0.2539 - val_accuracy: 0.8958\n",
            "Epoch 19/20\n",
            "10/10 [==============================] - 125s 13s/step - loss: 0.0914 - accuracy: 0.9656 - val_loss: 0.3098 - val_accuracy: 0.9167\n",
            "Epoch 20/20\n",
            "10/10 [==============================] - 126s 13s/step - loss: 0.0857 - accuracy: 0.9719 - val_loss: 0.2027 - val_accuracy: 0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.evaluate(validation_generator, steps=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vJII4SAYoNL",
        "outputId": "2b798c5e-b22e-4e28-ef80-b64843889448"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 7/10 [====================>.........] - ETA: 18s - loss: 0.2443 - accuracy: 0.9200WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
            "10/10 [==============================] - 46s 4s/step - loss: 0.2443 - accuracy: 0.9200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Paranmo = \"Paranmo\"\n",
        "tf.saved_model.save(model, Paranmo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LUOdoFMatEU",
        "outputId": "e2c68b49-7ce3-453e-c978-3729b1f0288f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: Paranmo/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash -s $Paranmo\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7ZnZndocBRt",
        "outputId": "613b9285-46b8-472f-dd17-0c2060074cdf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['input_1'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 224, 224, 3)\n",
            "      name: serving_default_input_1:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense_3'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded = tf.saved_model.load(Paranmo)"
      ],
      "metadata": {
        "id": "BEcNtxF2cKXI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTPuuUGdcRfQ",
        "outputId": "c9743bd2-0128-4ea3-d32f-0462e7da2cdb"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['serving_default']\n",
            "((), {'input_1': TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_1')})\n",
            "{'dense_3': TensorSpec(shape=(None, 10), dtype=tf.float32, name='dense_3')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(Paranmo)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa78V_wncXfY",
        "outputId": "ce435942-b1bb-4ebd-86d7-f7a8119bd018"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_file = 'converted_model_paranmo.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "PKvhm7_EdSr5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "with open(tflite_model_file, 'rb') as fid:\n",
        "    tflite_model = fid.read()\n",
        "    \n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "metadata": {
        "id": "-1BORFLNdZ5c"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['Daun Jambu Biji', 'Daun Kari', 'Daun Kemangi', 'Daun Kunyit', 'Daun Mint', \n",
        "               'Daun Pepaya', 'Daun Sirih', 'Daun Sirsak', 'Lidah Buaya', 'Teh Hijau']\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ],
      "metadata": {
        "id": "u0DI_Evsde0n"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('converted_model_paranmo.tflite')\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uaUHw4anfukJ",
        "outputId": "5bac2e9f-8f55-4698-f7cd-44f2ece0a8cf"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c78e7714-29f1-4e7f-9118-b81cfb4e5830\", \"converted_model_paranmo.tflite\", 61922880)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_65c6201c-a9fd-4a1a-852a-9e41e49def78\", \"labels.txt\", 117)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}